{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This code reads the raw data from a scio scan stored in a json file, then tries to decode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read settings file\n",
    "import json\n",
    "# Parst the command line arguments\n",
    "import argparse\n",
    "\n",
    "# Logging/output format setup\n",
    "import logging\n",
    "log = logging.getLogger('root')\n",
    "log.setLevel(logging.DEBUG)\n",
    "#logging.basicConfig(format='[%(asctime)s] %(levelname)8s %(module)15s: %(message)s')\n",
    "logging.basicConfig(format='[%(asctime)s] %(levelname)8s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# The SCIO library\n",
    "#import sciolib.sciolib as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = './'\n",
    "project_path_scans = project_path + '01_rawdata/scan_json/calibrations/'\n",
    "project_path_output = project_path + '02_processed_data/'\n",
    "# input file (TODO: replace with reading all files in folder)\n",
    "input_file = 'scio_scan_20211025_194204.json'\n",
    "output_file = 'scio_scan_20211025_194204_out.json'\n",
    "\n",
    "# Some general parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting functions\n",
    "#---------------------\n",
    "def encode_b64(bytestring):\n",
    "    # Encode and decode data as base64 (to store until we know what to do with it)\n",
    "    import base64\n",
    "    urlSafeEncodedBytes = base64.urlsafe_b64encode(bytestring)\n",
    "    urlSafeEncodedStr = str(urlSafeEncodedBytes, 'utf-8')\n",
    "    return(urlSafeEncodedStr)\n",
    "\n",
    "def decode_b64(b64string):\n",
    "    # Encode and decode data as base64 (to store until we know what to do with it)\n",
    "    import base64\n",
    "    bytestring = base64.urlsafe_b64decode(b64string)\n",
    "    return(bytestring)\n",
    "\n",
    "def read_raw_file(input_fn):\n",
    "    import json\n",
    "    \n",
    "    outdf = [ ]\n",
    "    with open(input_fn) as json_file:\n",
    "        jsondata = json.load(json_file)\n",
    "        for p in jsondata['scan']:\n",
    "            outdf.append(p['timestamp'])\n",
    "            outdf.append(p['t_cmos_before'])\n",
    "            outdf.append(p['t_chip_before'])\n",
    "            outdf.append(p['t_obj_before'])\n",
    "            outdf.append(p['t_cmos_after'])\n",
    "            outdf.append(p['t_chip_after'])\n",
    "            outdf.append(p['t_obj_after'])\n",
    "            outdf.append(decode_b64(p['part1']))\n",
    "            outdf.append(decode_b64(p['part2']))\n",
    "            outdf.append(decode_b64(p['part3']))\n",
    "    return(outdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_raw_file(project_path_scans + input_file)\n",
    "\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ef003e4eb037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAESCipher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'8032AB45611198F1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-ef003e4eb037>\u001b[0m in \u001b[0;36mdecrypt\u001b[1;34m(self, enc)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0miv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mcipher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODE_CBC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcipher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "from Crypto import Random\n",
    "from Crypto.Cipher import AES\n",
    "\n",
    "class AESCipher(object):\n",
    "\n",
    "    def __init__(self, key): \n",
    "        self.bs = AES.block_size\n",
    "        self.key = hashlib.sha256(key.encode()).digest()\n",
    "\n",
    "    def encrypt(self, raw):\n",
    "        raw = self._pad(raw)\n",
    "        iv = Random.new().read(AES.block_size)\n",
    "        cipher = AES.new(self.key, AES.MODE_CBC, iv)\n",
    "        return base64.b64encode(iv + cipher.encrypt(raw.encode()))\n",
    "\n",
    "    def decrypt(self, enc):\n",
    "        enc = base64.b64decode(enc)\n",
    "        iv = enc[:AES.block_size]\n",
    "        cipher = AES.new(self.key, AES.MODE_CBC, iv)\n",
    "        return self._unpad(cipher.decrypt(enc[AES.block_size:])).decode('utf-8')\n",
    "\n",
    "    def _pad(self, s):\n",
    "        return s + (self.bs - len(s) % self.bs) * chr(self.bs - len(s) % self.bs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _unpad(s):\n",
    "        return s[:-ord(s[len(s)-1:])]\n",
    "\n",
    "data = df[8]\n",
    "print(AESCipher.decrypt(data, '8032AB45611198F1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-11ea20130485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAESCipher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'8032AB45611198F1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-11ea20130485>\u001b[0m in \u001b[0;36mdecrypt\u001b[1;34m(self, enc)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0miv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mcipher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMODE_CBC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miv\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcipher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecrypt\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto import Random\n",
    "\n",
    "class AESCipher:\n",
    "    def __init__( self, key ):\n",
    "        self.key = key\n",
    "\n",
    "    def encrypt( self, raw ):\n",
    "        raw = pad(raw)\n",
    "        iv = Random.new().read( AES.block_size )\n",
    "        cipher = AES.new( self.key, AES.MODE_CBC, iv )\n",
    "        return base64.b64encode( iv + cipher.encrypt( raw ) ) \n",
    "\n",
    "    def decrypt( self, enc ):\n",
    "        enc = base64.b64decode(enc)\n",
    "        iv = enc[:16]\n",
    "        cipher = AES.new(self.key, AES.MODE_CBC, iv )\n",
    "        return unpad(cipher.decrypt( enc[16:] ))\n",
    "\n",
    "data = df[8]\n",
    "print(AESCipher.decrypt(data, '8032AB45611198F1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import binascii\n",
    "import gzip\n",
    "print(gzip.decompress(binascii.a2b_base64(b\"H4sIAAAAAAAA//NIzcnJVwjPL8pJAQBWsRdKCwAAAA==\")))\n",
    "\n",
    "import zlib\n",
    "zlib.decompress(bytearray(df[7]), 15+32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(data):\n",
    "    # Unpacks with an offset\n",
    "    temp = [ ]\n",
    "    data_length = len(data)\n",
    "    for j in range( data_length ):\n",
    "        temp.append( int(data[j]) )\n",
    "    return(temp)\n",
    "\n",
    "list_of_ints1 = convert_to_int(df[7])\n",
    "list_of_ints2 = convert_to_int(df[8])\n",
    "list_of_ints3 = convert_to_int(df[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from plotnine import *\n",
    "from plotnine.data import *\n",
    "\n",
    "plt = ggplot()\n",
    "plt = plt + geom_histogram(aes(list_of_ints1), binwidth=1, fill='blue', alpha=0.2)\n",
    "plt = plt + geom_histogram(aes(list_of_ints2), binwidth=1, fill='green', alpha=0.2)\n",
    "plt = plt + geom_histogram(aes(list_of_ints3), binwidth=1, fill='red', alpha=0.2)\n",
    "plt = plt + theme_bw()\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_list = sorted(glob.glob(project_path_scans + '*', recursive=True))\n",
    "\n",
    "# Create output path name\n",
    "#project_path_output = output_path + project_path.split('/')[-2] + '/'\n",
    "\n",
    "# Empty df to add data to\n",
    "df = pd.DataFrame([]) \n",
    "\n",
    "# For all files in the directory\n",
    "for fn_i, fn in enumerate(fn_list):\n",
    "    # Show status message\n",
    "    if(fn_i % 1 == 0): # % 20 to show every 20th file being loaded\n",
    "        print( '{:<07}'.format(str(round(fn_i * 100 / len(fn_list), 4))) + \"%\\t\\t\" + fn.split('\\\\')[-2] + '/' + fn.split('\\\\')[-1]) # Show status\n",
    "    \n",
    "    # Read raw data from file\n",
    "    data = read_raw_file(fn)\n",
    "    \n",
    "    p1 = convert_to_int(data[7])\n",
    "    p2 = convert_to_int(data[8])\n",
    "    p3 = convert_to_int(data[9])\n",
    "    temp = pd.DataFrame(list(zip(p1, p2, p3)), columns=['part1','part2','part3'])\n",
    "    temp['scan_id'] = fn_i\n",
    "    temp = temp.reset_index()\n",
    "    df = pd.concat([df, temp], axis=0, ignore_index=True)\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot(df, aes(x='part1', y=after_stat('count')))\n",
    "plt = plt + geom_histogram(binwidth=1, alpha=0.4)\n",
    "plt = plt + theme_bw() + facet_wrap('scan_id')\n",
    "plt\n",
    "ggsave(plt, 'part1.png', units='cm', width=30, height=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot(df, aes(x='part2', y=after_stat('count')))\n",
    "plt = plt + geom_histogram(binwidth=1, alpha=0.4)\n",
    "plt = plt + theme_bw() + facet_wrap('scan_id')\n",
    "plt\n",
    "ggsave(plt, 'part2.png', units='cm', width=30, height=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot(df, aes(x='part3', y=after_stat('count')))\n",
    "plt = plt + geom_histogram(binwidth=1, alpha=0.4)\n",
    "plt = plt + theme_bw() + facet_wrap('scan_id')\n",
    "plt\n",
    "ggsave(plt, 'part3.png', units='cm', width=30, height=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[df['scan_id'] == 1, 'part1']\n",
    "y = df.loc[df['scan_id'] == 0, 'part1']\n",
    "\n",
    "df_wide_p1 = df.pivot(['index'], columns='scan_id',values='part1').add_prefix('scan_')\n",
    "\n",
    "\n",
    "plt = ggplot(df_wide_p1)\n",
    "plt = plt + geom_point(aes(x='scan_0', y='scan_1'), colour='red', alpha=0.2)\n",
    "plt = plt + geom_point(aes(x='scan_0', y='scan_2'), colour='green', alpha=0.2)\n",
    "plt = plt + geom_point(aes(x='scan_0', y='scan_3'), colour='blue', alpha=0.2)\n",
    "plt = plt + geom_point(aes(x='scan_0', y='scan_4'), colour='purple', alpha=0.2)\n",
    "plt = plt + geom_point(aes(x='scan_0', y='scan_5'), colour='yellow', alpha=0.2)\n",
    "plt = plt + theme_bw()\n",
    "plt = plt + labs(x='Scan 0', y='Scans 1-5')\n",
    "print(plt)\n",
    "ggsave(plt, 'scan1_vs_2-6.png', units='cm', width=30, height=15)\n",
    "\n",
    "plt = ggplot(df)\n",
    "plt = plt + geom_point(aes(x='part1', y='part2', colour='scan_id'), alpha=0.2)\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR pairs\n",
    "\n",
    "\n",
    "result1 = convert_to_int(bytes(a ^ b for (a, b) in zip(df_wide_p1['scan_0'], df_wide_p1['scan_1'])))\n",
    "result2 = convert_to_int(bytes(a ^ b for (a, b) in zip(df_wide_p1['scan_0'], df_wide_p1['scan_2'])))\n",
    "#print(result1)\n",
    "#print(result2)\n",
    "result1 = convert_to_int(bytes(a ^ b for (a, b) in zip(df.loc[df['scan_id'] == 1, 'part1'], df.loc[df['scan_id'] == 1, 'part2'])))\n",
    "result2 = convert_to_int(bytes(a ^ b for (a, b) in zip(df.loc[df['scan_id'] == 2, 'part1'], df.loc[df['scan_id'] == 2, 'part2'])))\n",
    "\n",
    "\n",
    "plt = ggplot()\n",
    "plt = plt + geom_point(aes(x=result1, y=result2), alpha=0.2)\n",
    "plt = plt + theme_bw()\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify the OS\n",
    "import platform\n",
    "\n",
    "# To identify the device\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Exceptions / Assert errors\n",
    "import sys\n",
    "\n",
    "# Reading the SCIO through USB serial port\n",
    "import serial\n",
    "from serial.tools import list_ports_common\n",
    "\n",
    "READ_DATA = 2        #02\n",
    "READ_TEMPERATURE = 4 #04\n",
    "READ_BATTERY = 5     #05\n",
    "SET_READY = 14       #0e\n",
    "SET_LED = 11         #0b\n",
    "PROTOCOL = -70       #ba\n",
    "READ_BLE_ID = -124\n",
    "READ_DEV_ID = 1\n",
    "#RESET_LED = 50 # Does this work?\n",
    "# The 3 readings are: sample, sampleDark, sampleGradient\n",
    "# Whitereference is the scan of the box\n",
    "\n",
    "def find_scio_dev():\n",
    "    scio_dev = ''\n",
    "    # Check the platform\n",
    "    # https://dzone.com/articles/linux-system-mining-python\n",
    "    if(platform.uname().system == 'Linux'):\n",
    "        # TODO: Add check in case multiple /dev/ttyACMs ports are available #######################\n",
    "        for device in glob.glob('/dev/*'):\n",
    "            for pattern in ['ttyACM*']:\n",
    "                if re.compile(pattern).match(os.path.basename(device)):\n",
    "                    print('Device:           {0}'.format(device))\n",
    "                    scio_dev = device\n",
    "                    #manufacturer = self.read_line(device, 'manufacturer')\n",
    "                    #product = self.read_line(device, 'product')\n",
    "                    #print(manufacturer)\n",
    "                    #print(product)\n",
    "    elif(platform.uname().system == 'Windows'):\n",
    "        # TODO: Add check in case multiple COM ports are available\n",
    "        import serial.tools.list_ports as port_list\n",
    "        if(port_list.comports()):\n",
    "            scio_dev = port_list.comports()[0][0]\n",
    "    else:\n",
    "        log.error('This program currently only works on Linux & Windows.')\n",
    "        log.error('--> You are running ' + platform.uname().system + '.')\n",
    "        log.error('--> Exiting...')\n",
    "        quit()\n",
    "    if scio_dev == '':\n",
    "        print('No ttyACM (Linux) or COM (Windows) was detected: Is the SCIO on?')\n",
    "        quit()\n",
    "    # TODO: Add a check or manufacturer to determine that this is really the scio and not some arduino\n",
    "    log.info('Using port: ' + scio_dev)\n",
    "    return(scio_dev)\n",
    "\n",
    "def encode_b64(bytestring):\n",
    "    # Encode and decode data as base64 (to store until we know what to do with it)\n",
    "    import base64\n",
    "    urlSafeEncodedBytes = base64.urlsafe_b64encode(bytestring)\n",
    "    urlSafeEncodedStr = str(urlSafeEncodedBytes, 'utf-8')\n",
    "    return(urlSafeEncodedStr)\n",
    "\n",
    "def decode_b64(b64string):\n",
    "    # Encode and decode data as base64 (to store until we know what to do with it)\n",
    "    import base64\n",
    "    bytestring = base64.urlsafe_b64decode(b64string)\n",
    "    return(bytestring)\n",
    "\n",
    "def raw_read(filename):\n",
    "    import json\n",
    "    \n",
    "    outdf = [ ]\n",
    "    with open(filename) as json_file:\n",
    "        jsondata = json.load(json_file)\n",
    "        for p in jsondata['scan']:\n",
    "            outdf.append(p['timestamp'])\n",
    "            outdf.append(p['t_cmos_before'])\n",
    "            outdf.append(p['t_chip_before'])\n",
    "            outdf.append(p['t_obj_before'])\n",
    "            outdf.append(p['t_cmos_after'])\n",
    "            outdf.append(p['t_chip_after'])\n",
    "            outdf.append(p['t_obj_after'])\n",
    "            outdf.append(decode_b64(p['part1']))\n",
    "            outdf.append(decode_b64(p['part2']))\n",
    "            outdf.append(decode_b64(p['part3']))\n",
    "    return(outdf)\n",
    "        \n",
    "def raw_write(temp_before_df, temp_after_df, scan_df, filename):\n",
    "    # Saves a single scan as raw data to JSON\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # create the json file\n",
    "    jsondata = {}\n",
    "    jsondata['scan'] = []\n",
    "    jsondata['scan'].append({\n",
    "        'timestamp': timestamp,\n",
    "        't_cmos_before': temp_before_df[0], # cmosTemperature, chipTemperature, objectTemperature\n",
    "        't_chip_before': temp_before_df[1],\n",
    "        't_obj_before':  temp_before_df[2],\n",
    "        't_cmos_after': temp_after_df[0],\n",
    "        't_chip_after': temp_after_df[1],\n",
    "        't_obj_after':  temp_after_df[2],\n",
    "        'part1': encode_b64(scan_df[0]),\n",
    "        'part2': encode_b64(scan_df[1]),\n",
    "        'part3': encode_b64(scan_df[2])\n",
    "    })\n",
    "    \n",
    "    # Write data to JSON file\n",
    "    import json\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(jsondata, outfile, indent=4)\n",
    "    \n",
    "def protocol_message(cmd):\n",
    "    byte_command = b'' # empty initialisation\n",
    "    if(cmd == SET_LED):\n",
    "        # Setting the LED colour is special (longer command)\n",
    "        byte_command = struct.pack('<bbbbbbbbbbbbbbb',1,PROTOCOL,cmd,9,0,0,0,0,0,0,0,0,0,0)\n",
    "    else:\n",
    "        byte_command = struct.pack('<bbbbb',1,PROTOCOL,cmd,0,0)\n",
    "    return(byte_command)\n",
    "\n",
    "def read_data(scio_dev, command):\n",
    "    # Relevant functions\n",
    "    def decode_temperature(msg, message_length):\n",
    "        num_vars = message_length / 4 # divide by 4 because we are dealing with longs\n",
    "        data_struct = '<' + str(int(num_vars)) + 'L' # This is '<3l' or '<lll'\n",
    "        # Convert bytes to unsigned int\n",
    "        message_data = struct.unpack(data_struct, msg)\n",
    "        # Convert to temperatures\n",
    "        cmosTemperature = (message_data[0] - 375.22) / 1.4092 # Does this make sense? It's from the disassembled Android app...\n",
    "        chipTemperature = (message_data[1]) / 100\n",
    "        objectTemperature = message_data[2] / 100\n",
    "        temperature_df = [cmosTemperature, chipTemperature, objectTemperature]\n",
    "        return(temperature_df)\n",
    "    \n",
    "    def decode_dev_id(msg, message_length):\n",
    "        print(message_length)\n",
    "        print(msg)\n",
    "        print(len(msg))\n",
    "        #data_struct = '<8s8sH'\n",
    "        data_struct = '<H'\n",
    "        dev_df = struct.unpack(data_struct, msg[16:18])\n",
    "        print(dev_df)\n",
    "        return(dev_df)\n",
    "    \n",
    "    def decode_ble_id(msg, message_length):\n",
    "        #print(message_length)\n",
    "        print(msg)\n",
    "        print(msg[0:8])\n",
    "        print(msg[8:10]) # BLE firmware version\n",
    "        print(msg[10:50].decode('utf-8') ) # Unknown ID\n",
    "        print(msg[50:66].decode('utf-8') ) # device name\n",
    "        print(msg[66:131].decode('utf-8') ) # i2s tag\n",
    "        #data_struct = '<8sL16s64s'\n",
    "        data_struct = '<8sH40s16s64s'\n",
    "        ble_df = list(struct.unpack(data_struct, msg))\n",
    "        ble_df[2] = ble_df[2].decode('utf-8').strip()\n",
    "        ble_df[3] = ble_df[3].decode('utf-8').strip('\\x00')\n",
    "        ble_df[4] = ble_df[4].decode('utf-8').strip()\n",
    "        data_struct = '<8B'\n",
    "        ble_df = struct.unpack(data_struct, msg[0:8])\n",
    "        print(list(map(chr, ble_df)))\n",
    "        #print(''.join(r'\\x%02X' % ord(ch) for ch in msg[0:8] ))\n",
    "        print(ble_df)\n",
    "        return(ble_df)\n",
    "    \n",
    "    # Send reading command\n",
    "    # - - - - - - - - - - -\n",
    "    \n",
    "    # Create the message\n",
    "    byte_msg = protocol_message(command)\n",
    "    \n",
    "    # Open serial connection\n",
    "    try:\n",
    "        ser = serial.Serial(scio_dev)\n",
    "    except OSError as error:\n",
    "        log.error(error)\n",
    "        quit()\n",
    "    \n",
    "    # write the message to the serial device\n",
    "    ser.write(byte_msg)\n",
    "    \n",
    "    # Read the response\n",
    "    # - - - - - - - - - - -\n",
    "    \n",
    "    # Start reading the response\n",
    "    s = ser.read(1)\n",
    "    message_type    = struct.unpack('<b',s)[0]\n",
    "    \n",
    "    # Error check\n",
    "    assert (message_type == PROTOCOL), 'Wrong message type: {}'.format(message_type)\n",
    "    \n",
    "    # Data type\n",
    "    s = ser.read(1)\n",
    "    message_content = struct.unpack('<b',s)[0]\n",
    "    if(message_content == READ_TEMPERATURE):\n",
    "        log.debug('Receiving temperature data: ' + str(message_content))\n",
    "        # Data length\n",
    "        s = ser.read(2)\n",
    "        message_length = struct.unpack('<H',s)[0]\n",
    "        # Read the number of values specified by the message length\n",
    "        s = ser.read(message_length)\n",
    "        ser.close()\n",
    "        # decode that data\n",
    "        temperature_df = decode_temperature(s, message_length)\n",
    "        return(temperature_df)  # cmosTemperature, chipTemperature, objectTemperature\n",
    "    elif(message_content == READ_DATA):\n",
    "        raw_df = [ ]\n",
    "        log.debug('Receiving scan data: ' + str(message_content))\n",
    "        # get rid of first 2 sets to get\n",
    "        for i in range(3):\n",
    "            log.debug('--> Part: ' + str(i+1))\n",
    "            if(i > 0):\n",
    "                s = ser.read(1)\n",
    "                message_type    = struct.unpack('<b',s)[0]\n",
    "                s = ser.read(1)\n",
    "                message_content = struct.unpack('<b',s)[0]\n",
    "            s = ser.read(2)\n",
    "            message_length = struct.unpack('<H',s)[0]\n",
    "            s = ser.read(message_length)\n",
    "            raw_df.append(s)\n",
    "        ser.close()\n",
    "        return(raw_df)\n",
    "    elif(message_content == READ_DEV_ID):\n",
    "        s = ser.read(2)\n",
    "        message_length = struct.unpack('<H',s)[0]\n",
    "        # Read the number of values specified by the message length\n",
    "        s = ser.read(message_length)\n",
    "        ser.close()\n",
    "        # decode that data\n",
    "        dev_df = decode_dev_id(s, message_length)\n",
    "    elif(message_content == READ_BLE_ID):\n",
    "        s = ser.read(2)\n",
    "        message_length = struct.unpack('<H',s)[0]\n",
    "        # Read the number of values specified by the message length\n",
    "        s = ser.read(message_length)\n",
    "        ser.close()\n",
    "        # decode that data\n",
    "        ble_df = decode_ble_id(s, message_length)\n",
    "    else:\n",
    "        log.debug('Receiving unknown message: ' + str(message_content))\n",
    "        \n",
    "    # This divides one list by another\n",
    "    #print([n/d for n, d in zip(df[0], df[2])])\n",
    "    \n",
    "def decode_data(raw_df):\n",
    "    # 40-bit decoding functions\n",
    "    def getU32(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[0] & 255)) + (( int(dat[1] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[3] & 255)) << 24) )\n",
    "        \n",
    "    def getU32_le(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[3] & 255)) + (( int(dat[2] & 255)) << 8)) + (( int(dat[1] & 255)) << 16)) + (( int(dat[0] & 255)) << 24) )\n",
    "            \n",
    "    def unpackU32(data, header):\n",
    "        # Assuming 414 bands (4*414=1656). It is possible that the SCIO has more bands, but is noisy on both ends\n",
    "        temp = [ ]\n",
    "        footer = 476 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 332 - header;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/4) ):\n",
    "            temp.append( getU32(data, j*4+header) )\n",
    "        return(temp)\n",
    "        \n",
    "    # 40-bit decoding functions\n",
    "    def getU40(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[0] & 255)) + (( int(dat[1] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[3] & 255)) << 24) + (( int(dat[4] & 255)) << 32) )\n",
    "            \n",
    "    def unpackU40(data, header):\n",
    "        temp = [ ]\n",
    "        footer = 145 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 0;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/5) ):\n",
    "            temp.append( getU40(data, j*5+header) / 100000000)\n",
    "        return(temp)\n",
    "        \n",
    "    def getU40_le(data, index):\n",
    "        dat = data[index:(index+5)]\n",
    "        return float( ((( int(dat[4] & 255)) + (( int(dat[3] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[1] & 255)) << 24) + (( int(dat[0] & 255)) << 32) )\n",
    "        \n",
    "    def unpackU40_le(data, header):\n",
    "        temp = [ ]\n",
    "        footer = 145 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 0;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/5) ):\n",
    "            temp.append( getU40_le(data, j*5+header) / 100000000)\n",
    "        return(temp)\n",
    "        \n",
    "    # Function to try to decode\n",
    "    def decode(raw_df, header):\n",
    "        df = [ ]\n",
    "        for part in range(len(raw_df)):\n",
    "            if(part == 2):\n",
    "                header = 0\n",
    "            df.append( unpackU32(raw_df[part], header) ) #df.append( unpackU40(raw_df[part], header) )\n",
    "        return(df)\n",
    "\n",
    "    def unpackU32b(data, header, footer):\n",
    "        # Unpacks with an offset\n",
    "        temp = [ ]\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/4) ):\n",
    "            temp.append( getU32b(data, j*4+header) ) # Was getU32(\n",
    "        return(temp)\n",
    "        \n",
    "    def getU64(data, index):\n",
    "        dat = data[index:(index+8)]\n",
    "        out = struct.unpack('<Q', dat)\n",
    "        return(out[0])\n",
    "    \n",
    "    def unpackU64(data, header, footer):\n",
    "        # Unpacks with an offset\n",
    "        temp = [ ]\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/8) ):\n",
    "            temp.append( getU64(data, j*8+header) )\n",
    "        return(temp)\n",
    "        \n",
    "    # iterate over possible number of headers in order to find solution\n",
    "    # U64\n",
    "    num_vars = 207\n",
    "    var_size = 8\n",
    "    diff_scan = len(raw_df[0]) - num_vars*var_size\n",
    "    print('diff_scan: ' + str(diff_scan))\n",
    "    diff_cal =  len(raw_df[2]) - num_vars*var_size\n",
    "    print('diff_cal:  ' + str(diff_cal))\n",
    "    solution = False\n",
    "    for i in range(diff_scan+1):\n",
    "        #if(solution):\n",
    "        #    break\n",
    "        print(i, diff_scan - i)\n",
    "        df = [ ]\n",
    "        df.append(unpackU64(raw_df[0], i, diff_scan - i)) # scan\n",
    "        df.append(unpackU64(raw_df[2], 0, 0))  # calibration\n",
    "        reflectance = [n/d for n, d in zip(df[0], df[1])]\n",
    "        if(all(k <= 1.0 for k in reflectance)):\n",
    "            solution = True\n",
    "            log.debug('Solution with scan header ' + str(i) )\n",
    "            break\n",
    "    \n",
    "    # U32\n",
    "    num_vars = 331\n",
    "    var_size = 4\n",
    "    diff_scan = len(raw_df[0]) - num_vars*var_size\n",
    "    print('diff_scan: ' + str(diff_scan))\n",
    "    diff_cal =  len(raw_df[2]) - num_vars*var_size\n",
    "    print('diff_cal:  ' + str(diff_cal))\n",
    "    solution = False\n",
    "    for i in range(diff_scan+1):\n",
    "        for j in range(diff_cal+1):\n",
    "            #if(solution):\n",
    "            #    break\n",
    "            print(i, diff_scan - i, j, diff_cal - j)\n",
    "            df = [ ]\n",
    "            df.append(unpackU32b(raw_df[0], j, diff_cal - j)) # scan\n",
    "            df.append(unpackU32b(raw_df[2], i, diff_scan - i))  # calibration\n",
    "            reflectance = [n/d for n, d in zip(df[0], df[1])]\n",
    "            if(all(k <= 1.0 for k in reflectance)):\n",
    "                solution = True\n",
    "                log.debug('Solution with scan header ' + str(i) + ' and cal. header ' + str(j))\n",
    "                break\n",
    "        \n",
    "    solution = False\n",
    "    for h in range(332): #range(145):\n",
    "        reflectance = [ ]\n",
    "        df = decode(raw_df,h)\n",
    "        reflectance.append([n/d for n, d in zip(df[0], df[2])])\n",
    "        reflectance.append([n/d for n, d in zip(df[1], df[2])])\n",
    "        if(all(i <= 1.0 for i in reflectance[0])):\n",
    "            solution = True\n",
    "            log.debug('Solution with header ' + str(header))\n",
    "    if(not solution):\n",
    "        log.debug('No solution found')\n",
    "    print(reflectance)\n",
    "    return(reflectance)\n",
    "\n",
    "def decode_data2(raw_df, cal_df):\n",
    "    # 40-bit decoding functions\n",
    "    def getU32(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[0] & 255)) + (( int(dat[1] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[3] & 255)) << 24) )\n",
    "        \n",
    "    def getU32b(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        out = struct.unpack('<q', dat)\n",
    "        return(out[0])\n",
    "        \n",
    "    def getU32_le(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[3] & 255)) + (( int(dat[2] & 255)) << 8)) + (( int(dat[1] & 255)) << 16)) + (( int(dat[0] & 255)) << 24) )\n",
    "            \n",
    "    def unpackU32(data, header):\n",
    "        # Assuming 414 bands (4*414=1656). It is possible that the SCIO has more bands, but is noisy on both ends\n",
    "        temp = [ ]\n",
    "        footer = 476 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 332 - header;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/4) ):\n",
    "            temp.append( getU32(data, j*4+header) )\n",
    "        return(temp)\n",
    "        \n",
    "    # 40-bit decoding functions\n",
    "    def getU40(data, index):\n",
    "        dat = data[index:(index+4)]\n",
    "        return float( ((( int(dat[0] & 255)) + (( int(dat[1] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[3] & 255)) << 24) + (( int(dat[4] & 255)) << 32) )\n",
    "            \n",
    "    def unpackU40(data, header):\n",
    "        temp = [ ]\n",
    "        footer = 145 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 0;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/5) ):\n",
    "            temp.append( getU40(data, j*5+header) / 100000000)\n",
    "        return(temp)\n",
    "        \n",
    "    def getU40_le(data, index):\n",
    "        dat = data[index:(index+5)]\n",
    "        return float( ((( int(dat[4] & 255)) + (( int(dat[3] & 255)) << 8)) + (( int(dat[2] & 255)) << 16)) + (( int(dat[1] & 255)) << 24) + (( int(dat[0] & 255)) << 32) )\n",
    "        \n",
    "    def unpackU40_le(data, header):\n",
    "        temp = [ ]\n",
    "        footer = 145 - header\n",
    "        if(len(data) == 1656):\n",
    "            footer = 0;\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/5) ):\n",
    "            temp.append( getU40_le(data, j*5+header) / 100000000)\n",
    "        return(temp)\n",
    "        \n",
    "    # Function to try to decode\n",
    "    def decode(raw_df, header):\n",
    "        df = [ ]\n",
    "        for part in range(len(raw_df)):\n",
    "            if(part == 2):\n",
    "                header = 0\n",
    "            df.append( unpackU32(raw_df[part], header) ) #df.append( unpackU40(raw_df[part], header) )\n",
    "        return(df)\n",
    "\n",
    "    def unpackU32b(data, header, footer):\n",
    "        # Unpacks with an offset\n",
    "        temp = [ ]\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/4) ):\n",
    "            temp.append( getU32(data, j*4+header) )\n",
    "        return(temp)\n",
    "    \n",
    "        \n",
    "    def getU64(data, index):\n",
    "        dat = data[index:(index+8)]\n",
    "        out = struct.unpack('<Q', dat)\n",
    "        return(out[0])\n",
    "    \n",
    "    def unpackU64(data, header, footer):\n",
    "        # Unpacks with an offset\n",
    "        temp = [ ]\n",
    "        data_length = len(data) - header - footer\n",
    "        for j in range( int(data_length/8) ):\n",
    "            temp.append( getU64(data, j*8+header) )\n",
    "        return(temp)\n",
    "        \n",
    "    # iterate over possible number of headers in order to find solution\n",
    "    # U64\n",
    "    num_vars = 331\n",
    "    var_size = 5\n",
    "    diff_scan = len(raw_df[0]) - num_vars*var_size\n",
    "    print('diff_scan: ' + str(diff_scan))\n",
    "    diff_cal =  len(cal_df[0]) - num_vars*var_size\n",
    "    print('diff_cal:  ' + str(diff_cal))\n",
    "    solution = False\n",
    "    for i in range(diff_scan+1):\n",
    "        for j in range(diff_cal+1):\n",
    "            #if(solution):\n",
    "            #    break\n",
    "            print('U40', i, diff_scan - i, j, diff_cal - j)\n",
    "            df = [ ]\n",
    "            df.append(unpackU64(raw_df[0], i, diff_scan - i)) # scan\n",
    "            df.append(unpackU64(cal_df[0], j, diff_cal - j))  # calibration # shourld be j\n",
    "            reflectance = [n/d for n, d in zip(df[0], df[1])]\n",
    "            if(all(k <= 1.0 for k in reflectance)):\n",
    "                solution = True\n",
    "                log.debug('Solution with scan header ' + str(i) )\n",
    "                break\n",
    "            break # DEBUG\n",
    "    print('U40 not found')\n",
    "    \n",
    "    # U32\n",
    "    num_vars = 331\n",
    "    var_size = 4\n",
    "    diff_scan = len(raw_df[0]) - num_vars*var_size\n",
    "    print('diff_scan: ' + str(diff_scan))\n",
    "    diff_cal =  len(cal_df[0]) - num_vars*var_size\n",
    "    print('diff_cal:  ' + str(diff_cal))\n",
    "    solution = False\n",
    "    for i in range(1, diff_scan+1):\n",
    "        for j in range(1, diff_cal+1):\n",
    "            #if(solution):\n",
    "            #    break\n",
    "            print('U32', i, diff_scan - i, j, diff_cal - j)\n",
    "            df = [ ]\n",
    "            df.append(unpackU32b(raw_df[0], j, diff_cal - j)) # scan\n",
    "            df.append(unpackU32b(cal_df[0], i, diff_scan - i))  # calibration\n",
    "            reflectance = [n/d for n, d in zip(df[0], df[1])]\n",
    "            if(all(k <= 1.0 for k in reflectance)):\n",
    "                solution = True\n",
    "                log.debug('Solution with scan header ' + str(i) + ' and cal. header ' + str(j))\n",
    "                break\n",
    "            break # DEBUG\n",
    "        \n",
    "    diff = len(raw_df[0]) - num_vars*var_size\n",
    "    solution = False\n",
    "    for h in range(1, diff+1): #range(145):\n",
    "        df = [ ]\n",
    "        df.append(unpackU32b(raw_df[0], i, diff - i)) # scan\n",
    "        df.append(unpackU32b(cal_df[0], i, diff - i))  # calibration\n",
    "        df.append(unpackU32b(raw_df[1], i, diff - i)) # scan\n",
    "        df.append(unpackU32b(cal_df[1], i, diff - i))  # calibration\n",
    "        reflectance = [ ]\n",
    "        reflectance.append([n/d for n, d in zip(df[0], df[1])])\n",
    "        reflectance.append([n/d for n, d in zip(df[2], df[3])])\n",
    "        temp = [ ]\n",
    "        temp.append([(a+b)/2 for a, b in zip(df[0], df[2])])\n",
    "        temp.append([(a+b)/2 for a, b in zip(df[1], df[3])])\n",
    "        reflectance = [ ]\n",
    "        reflectance.append([n/d for n, d in zip(temp[0], temp[1])])\n",
    "        if(all(i <= 1.0 for i in reflectance[0])):\n",
    "            solution = True\n",
    "            log.debug('Solution with header ' + str(header))\n",
    "    if(not solution):\n",
    "        log.debug('No solution found')\n",
    "    print(reflectance)\n",
    "    return(reflectance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw json file\n",
    "json_df = raw_read(project_path_scans + input_file)\n",
    "df = json_df[7:10] # Element 10 is not included...\n",
    "scan_df = decode_data2(df, scan_cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_fct(calibrate, infile, outfile, calfile, protocol, raw):\n",
    "    if(calibrate): # DEBUG!!!\n",
    "        log.debug('We were told to calibrate')\n",
    "    log.info('Input/output')\n",
    "        \n",
    "    # Find the home folder (temporary)\n",
    "    from pathlib import Path\n",
    "    json_dir = str(Path.home())\n",
    "    \n",
    "    # Check if we need to scan\n",
    "    if(infile is not None):\n",
    "        # Input comes from a file\n",
    "        log.info('--> Input through:    ' + json_dir + '/' + infile)\n",
    "        log.info('--> Output file name: ' + 'N/A')\n",
    "        # Read the raw json file\n",
    "        json_df = scio.raw_read(json_dir + '/' + infile)\n",
    "        scan_raw_df = json_df[7:10] # Element 10 is not included...\n",
    "    else:\n",
    "        # We have to scan (Only USB currently works)\n",
    "        log.info('--> Input through:    ' + protocol)\n",
    "        log.info('--> Output file name: ' + outfile)\n",
    "        \n",
    "        # Try to find the device\n",
    "        scio_device = scio.find_scio_dev()\n",
    "    \n",
    "        # https://makersportal.com/blog/2018/2/25/python-datalogger-reading-the-serial-output-from-arduino-to-analyze-data-using-pyserial\n",
    "        try: # Make sure to close the serial port if it was still open\n",
    "            ser.close()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # Read temperature before scanning\n",
    "        temp_before_df = scio.read_data(scio_device, 4) # 4 = read temperature\n",
    "        log.info('CMOS T: {:.3f}'.format(temp_before_df[0])) # cmosTemperature, chipTemperature, objectTemperature\n",
    "        log.info('Chip T: {:.3f}'.format(temp_before_df[1]))\n",
    "        log.info('Obj. T: {:.3f}'.format(temp_before_df[2]))\n",
    "    \n",
    "        # Scan and decode\n",
    "        scan_raw_df = scio.read_data(scio_device, 2) # 2 = read data\n",
    "    \n",
    "        # Read temperature after scanning\n",
    "        temp_after_df = scio.read_data(scio_device, 4)\n",
    "    \n",
    "        # Path to output file within home directory\n",
    "        if(outfile == 'scio-scan'):\n",
    "            # The default file name was given!\n",
    "            log.info('WARNING! The default file was used. Any existing previous file will be overwritten!')\n",
    "            \n",
    "        # Save the file\n",
    "        log.debug('Writing raw scan to: ' + json_dir + '/' + outfile + '.json')\n",
    "        # Saves the raw data. In the end, I'll want to save the scan as a CSV\n",
    "        scio.raw_write(temp_before_df, temp_after_df, scan_raw_df, json_dir + '/' + outfile + '.json')\n",
    "    \n",
    "    #print(scio.read_data(scio_device, 1)) # Read device ID\n",
    "    #print(scio.read_data(scio_device, -124)) # Read BLE ID\n",
    "    \n",
    "    if(calfile is not None):\n",
    "        # read calibration file\n",
    "        log.info('--> Calibration file name: ' + 'N/A')\n",
    "        # Read the raw json file\n",
    "        json_df = scio.raw_read(json_dir + '/' + calfile)\n",
    "        scan_cal_df = json_df[7:10] # Element 10 is not included...\n",
    "    \n",
    "    log.info('Trying to decode data')\n",
    "    #scan_df = scio.decode_data(scan_raw_df) # DOES NOT YET WORK\n",
    "    scan_df = scio.decode_data2(scan_raw_df, scan_cal_df)\n",
    "    #print(scan_df) #DEBUG\n",
    "    #log.debug('Number of scans in data:  ' + str(len(scan_df)))\n",
    "    #log.debug('Number of variables/scan: ' + str(len(scan_df[0])))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn  = './01_rawdata/scan_json/skin.json'\n",
    "output_fn = ''\n",
    "\n",
    "main_fct(False, infile, outfile, calfile, protocol, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scio",
   "language": "python",
   "name": "scio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
